{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "import re,os,csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAKE STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAKE_data_dir = './rake_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rake_files =  ['ClinTrials_RAKE.csv','NIH_RAKE.csv','PubMed_RAKE.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = pd.read_csv('rake_output/PubMed_RAKE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_kw_rake_cols(fileName):\n",
    "    df = pd.read_csv(fileName)\n",
    "    kw_cols = [x  for x in df.columns.tolist() if x.startswith('KW_RAKE')]\n",
    "    df['Keywords'] = df[kw_cols[0]]\n",
    "    for i in range(1,len(kw_cols)): \n",
    "        df['Keywords'] =  df['Keywords'] + df[kw_cols[i]]\n",
    "        df['Keywords'] =  df.Keywords.str.replace('\\]\\[' , ',',regex=False)\n",
    "    df['Keywords'] =  df.Keywords.str.replace('\\]|\\[' , '',regex=True)\n",
    "    df.drop([x  for x in df.columns.tolist() if x.startswith('Unnamed')],axis=1,inplace=True)\n",
    "    df.drop(kw_cols,axis=1,inplace=True)\n",
    "    df.to_csv('preProc_' + os.path.basename(fileName),index=False)\n",
    "    return 'preProc_' + os.path.basename(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preProc_RAKE_files = [join_kw_rake_cols(RAKE_data_dir + '/' + f) for f in rake_files]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preProc_ClinTrials_RAKE.csv',\n",
       " 'preProc_NIH_RAKE.csv',\n",
       " 'preProc_PubMed_RAKE.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preProc_RAKE_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUTOPHRASE STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOP_data_dir = './Auto_phrase/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "autop_files =  ['clinical_data_output_withkeyword.csv','NIH_data_output_withkeyword.csv','pubmed_data_output_withkeyword.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Bad files, cant be used. Ravi to update and add cleaned up files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_data_dir = './new_data/Data_with_keywords/Data_with_keywords/LDA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autop_files =  ['clinicTrial_LDA_cat_output.csv','pubMed_LDA_cat_output.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Map across 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData_dict_PTR = {'pubmed' : ['preProc_PubMed_RAKE.csv','pubMed_LDA_cat_output.csv'],\n",
    "                   'clinictrial' : ['preProc_ClinTrials_RAKE.csv','clinicTrial_LDA_cat_output.csv'],\n",
    "                   'nih': ['preProc_NIH_RAKE.csv']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge keywords across 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('CONSOLIDATED_FOR_ENTITY_MATCHING'):\n",
    "    os.makedirs('CONSOLIDATED_FOR_ENTITY_MATCHING')\n",
    "    \n",
    "for k in allData_dict_PTR.keys():\n",
    "    df_1 = pd.read_csv(allData_dict_PTR[k][0])\n",
    "    print(f'[INFO] consolidating for : {k}')\n",
    "    for n in range(1,(len(allData_dict_PTR[k]))):\n",
    "        df_1 = df_1.merge(pd.read_csv(allData_dict_PTR[k][n])[['Title','Keywords']], left_on=['Title'],right_on=['Title'])\n",
    "        df_1['Keywords'] = df_1.Keywords_x + df_1.Keywords_y\n",
    "        df_1['Keywords'] = df_1.Keywords.str.replace('\\'','').str.split(' ').apply(lambda x : list(set(x)))\n",
    "        df_1.drop(['Keywords_x','Keywords_y'],axis=1,inplace=True)\n",
    "    df_1.to_csv('CONSOLIDATED_FOR_ENTITY_MATCHING/' + 'all_' + k + '_keyWords_FINAL.csv',index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
